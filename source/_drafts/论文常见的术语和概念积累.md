---
title: 论文常见的术语和概念积累
tags:
---

## 前言
积累。有可能写的是错误的，因为我也是从网上看来了，没有经过仔细验证。

## 常见术语与概念

### auto decoder 
AutoEncoder 是 Feedforward Neural Network 的一种，曾经主要用于数据的降维或者特征的抽取，而现在也被扩展用于生成模型中。与其他 Feedforward NN 不同的是，其他 Feedforward NN 关注的是 Output Layer 和错误率，而 AutoEncoder 关注的是 Hidden Layer；其次，普通的 Feedforward NN 一般比较深，而 AutoEncoder 通常只有一层 Hidden Layer。

原始的 AutoEncoder 结构很简单：Input Layer、Hidden Layer、Output Layer。此网络的约束有：
1. Hidden Layer 的维度要远小于 Input Layer
2. Output 用于重构 Input，也即让误差L(Input, Output)最小



### KL散度
KL散度又叫相对熵，它的定义如下：设p(x)和q(x)是X取值的两个概率分布，则p对q的KL散度（相对熵）为：
![loading](KL_divergence.png)

在一定程度上，熵可以度量两个随机变量的距离。KL散度是两个概率分布P和Q差别的非对称性的度量。当两个随机分布相同时，它们的KL散度为零，当两个随机分布的差别增大时，它们的KL散度也会增大。
KL散度具有以下两个性质：
1. 尽管KL散度从直观上是个度量或距离函数，但它并不是一个真正的度量或者距离，因为它不具有对称性，即：
<img src = 'kl_attr1.png' height = '70px'>
2. KL散度的值为非负值，即：
<img src = 'kl_attr2.png' height = '70px'>


### 流形
流形（英语：Manifolds），是局部具有欧几里得空间性质的空间，是欧几里得空间中的曲线、曲面等概念的推广。欧几里得空间就是最简单的流形的实例。地球表面这样的球面则是一个稍微复杂的例子。一般的流形可以通过把许多平直的片折弯并粘连而成。 ---维基百科

### wasserstein distance / 瓦瑟斯坦距离
pass